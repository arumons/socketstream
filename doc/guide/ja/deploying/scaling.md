### ZeroMQ によるスケーリング

スケーリングは0.2のリリースにて主眼となっています。我々が今日所有しているものはこれで終わりにできるような決定的なアーキテクチャでは決してありません。しかしリアルタイムアプリをリリースし、複数のサーバーにて動作するよう拡張が必要になったときに幾つかの選択肢を良い具合に提供できるようになりました。

最初に言ってしまうとスケーリングは簡単ではありません。高速なシングルスレッドで動作するアプリ（SocketStream 0.1 のような）を作ることは簡単ですが、一旦アプリがシングルCPUの処理能力を超えてしまうと、ほとんど役に立たなくなってしまいます。

SocketStream におけるボトルネックは HTTP レイヤの中に必ずしもあるというわけではないため（実際、基本的に SocketStream が送る HTTP アセット は非常に小さなものです）`cluster` や `multi-node` といった Node ライブラリを使うだけでは十分ではありません。たとえこれらのライブラリがマルチコアにおけるパフォーマンスを向上させたとしても、物理的なハードウェアの限界を超えてしまったらどうなるのでしょうか？同時にマルチコアと複数のサーバーに対してスケールできるようなアプローチが必要なのは明確でした。

SocketStream 0.2 ではフレームワークを２つの要素に分解することでこの問題を解決しています：フロントエンドでは全ての HTTP トラフィック、websockets、API リクエストを処理し、バックエンドでは Redis やMongoDB（または、他のDB）とやりとりを行い、/app/server や /app/shared 内のメソッドを実行します。SocketStream 0.2 のソースコードを見てみると /lib ディレクトリの中が綺麗に分割されていることがわかるでしょう。

フロントエンドとバックエンドはお互いに非同期RPCレイヤのみにてやりとりをするよう整形されています。このRPCレイヤは複数の転送手段をサポートしています。

1. シングルプロセスモードでは、メッセージオブジェクトを単純にインメモリに置き換えます。スピードを最大限に重視するため、シリアライゼーションは行いません

2. マルチプロセス（クラスタ）モードではメッセージは JSON 形式にシリアライズされ、高速な ZeroMQ ソケットに送られます

ZeroMQ は非常に高速かつ、クラスタにサーバーを追加、削除を簡単に行えるため選択されました。

RPC メッセージは現在レイヤ間でやりとりを行うための唯一の手段であるため、データベースや Redis を安全なサブネットに配置や、あなたのデータと外部から送られた不正なリクエストの間にセキュリティ層を配置することを可能にするといったことが可能になります。

下記に示すクラスタの機能やコマンドを有効にするには ZeroMQ をインストールする必要があります。これには数分しかかかりません。インストール方法を見るには `socketstream help` とタイプしてください。

ZeroMQ をインストールしたら、それぞれのコンポーネントを確認し、それぞれがどのように独立して複数のマシーンで動作するのかを見てみましょう。


__socketstream frontend__

このコマンドは現在 HTTP API とSocket.IO 関連を含んだ静的なリクエストを処理するシングルスレッドプロセスを立ち上げます。近い内に追加で子プロセスを立ち上げるようになるでしょう。これにはおそらく node 0.5 新しく追加される child_process.forc() メソッドを使うと思われます。


★ このコマンドは複数のマシンにて実行することができますが、これは複数のIPに対しての websocket 回線をロードバランシングする手段（AWS で使われているのを含め、ほとんどのロードバランサはこの機能を持っていません）が見つかるまでは意味がありません。HAProxy? フロントエンドスケーリングについては我々が現在開発中のプロジェクトのいくつかにて必要とされているため、将来のリリースで提供することを保証します。

__socketstream backend__

このコマンドは軽量なプロセスマネージャを起動します。これは順番に'worker'子プロセスを立ち上げ、フロントエンドサーバーから送られた RPC リクエストを処理します。これらの worker は全てのリクエストを /app/server、/app/shared、そして将来追加される /app/models 内のメソッドに送ります。クライアントから送られたハートビートや、切断といった内部コマンドも同様に処理を行います。

バックエンド worker プロセスはそれぞれ直接 Redis やその他データベースと接続します。近頃のサーバーは大部分がデュアルコア（少なくとも）であるため、デフォルトでは worker プロセスは２つ立ち上がります。
この数は -w オプションにて変更可能です。

★ 一度 /app/config.coffee にて ソケットの設定を行うと（下記を見てください）、アプリケーションの必要に応じてバックエンド worker プロセス
Once you have configured the sockets in /app/config.coffee (see below), you may start and stop as many of these back end worker processes as your application needs. Should any worker process (or the entire box) die, the remaining processes will automatically take over. Obviously if your app is very database intensive, or needs to do a lot of processing / calculations, you'll want to start more back end workers to keep response times low.


__socketstream router__

これは分散アーキテクチャにとって三番目かつ、最後のピースです。固定された TCP ポートと結びつき、フロントエンドとバックエンドサーバーを自由に結びつける唯一のプロセスです。
名前が示すとおり、 これは フロントエンドとバックエンド間のメッセージを発送／仲介します。router は単純にバイナリメッセージをあるソケットから別のソケットに受け渡しするだけなので、大量のトラフィックを処理することができます。

router は Redis からのイベントを仲介する機能もあるため、フロントエンドサーバーは直接 Redis とやりとりをする必要がありません（すべきでもありません）。router として起動できるのは一つのクラスタにつき一つですが、理想としてはそのマシンは２つのNICを持つことになるでしょう。それによってファイアウォールとしてバックエンドサーバーの保護や、Redis やその他のデーバーベースを外部の攻撃から守ることができます。

万一 router プロセスがクラッシュした場合、マネージャープロセス（'socketstream router' を実行した際にデフォルトで起動します）によって自動的に再開します。

これら３つのコマンドを別々のターミナルウィンドウにてそれぞれ実行してみましょう。複数のサーバーで立ち上げる準備ができたなら次のセクションを読む必要があるでしょう。


#### SocketStream に接続方法を伝える

★ 複数のサーバーでアプリを動かすのはとても複雑で大量のマニュアルを読まなければいけないと思っているかもしれません。ありがたいことに必要な設定は /app/confing.coffee にあるコメントアウトされた３行を `socketstream router` が動作しているサーバーとZeroMQが動作しているサーバーのIPアドレスに置き換えるだけです。

さらなる詳細：

まず、router として機能するサーバーをどれにするか決め、少なくともひとつの静的なIPアドレスを割り振ります。router に２つのNICをインストールというアドバイスを受け入れるのなら（これによって router はファイアウォールとして動作するようになります）、２つの静的なIPアドレスを配置したくなるでしょう。一つはフロントエンドサーバー用、もう一つはバックエンドサーバー用にです。

IPアドレスがわかったら /app/config.coffee ファイルにある 'cluster' セクションのコメントを外し、router のIPアドレスで置き換えてください。どのポート番号でも設定できますが、それぞれのソケットは異なるアドレス：ポート番号の組み合わせにしてください。

次にgit にアプリケーションをコミットし、全てのサーバにてアプリが最新になっていることを確認します。router を開始するとフロントエンドとバックエンドサーバーが立ち上がります。SocketStream はフロントエンド／バックエンドサーバーの数やどんなIPアドレスが割り振られているかについて気にしません。router のIPのみが config ファイルにて設定されている必要があります。

今後さらに cluster の設定を簡単かつ自動で行われるよう改善していく予定です。


#### 将来に向けて

★ 今後さらに全ての単一障害点がなくなるよう開発を続けていきます。現在あなたのアプリが一夜にして成功を収めた場合、うってつけの選択があります。

もし２つ以上のクラスタを異なる データセンター／availability zone で運用しようと思っていんるのなら、それぞれに router が存在することになります。試したわけではありませんが、理屈の上ではそれぞれのクラスタから共通の Redis にアクセスできるはずです。

もしこれが非常に複雑すぎると感じたならスケーリングのことは一旦忘れてしまってください。`socketstream single` とすることで高速なシングルプロセスが起動します。このコマンドは３つのサーバー要素をひとつにまとめて立ち上げるのと同じ役割になります。


#### コントリビューション

もしあなたが ZeroMQ のエキスパートで私たちのスケーリング活動に興味を持ったなら是非ご意見を聞かせてください！ベンチマーク用のチューニングに関心がある方も是非連絡をお願いします。我々は既にベンチマークを用意していますが（`socketstream benchmark`）もっと多くのケースが必要なのです。
